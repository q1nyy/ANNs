# 神经网络(artificial neural network，ANNs)

神经网络入门（不如说是摸到了神经网络的一根毛）

[入坑视频](https://www.bilibili.com/video/BV1GC4y15736/?spm_id_from=333.1007.tianma.1-3-3.click&vd_source=0ee8fa26252a6e1ba9504c45ec9c7493)

操作系统：windows10

python版本：Python 3.10.9

框架：PyTorch

### 手写数字识别项目

##### PyTorch

- 代码简洁、符合人类思维，容易上手
- 少量代码就能完成机器学习任务

##### MNIST数据集

- 手写数字图片7万张
- 训练挤6万张 + 测试集1万张

训练集：调整神经网络的参数
测试集：评估网络性能

MNIST图片：

- 大小：$28 \times 28$ 像素
- 灰度值：$0 $ 到 $255$
- 标记：真实值

#### 如何设计神经网络

样例：

![image-20231130231139881](C:\Users\qyypy\AppData\Roaming\Typora\typora-user-images\image-20231130231139881.png)

1. 把像素重新排列为一维阵列，这就构成了神经网络的第0层节点，每个节点值为0或者1
   

   <img src="C:\Users\qyypy\AppData\Roaming\Typora\typora-user-images\image-20231130231227418.png" style="zoom:30%;" />

2. 构造下一层节点值：
   给第一层节点编号$x^0_0$ 、$x^0_1$ ......以此类推，那么第1层节点第0个节点的数值$x^1_0$ 是这样计算的：
   $$
   x^1_0 = (a^0_{0, 0} * X^0_0 + b^0_{0, 0}) + (a^0_{1, 0} * X^0_{1, 0} + b^0_{1, 0})
    + ... + (a^0_{n, 0} * X^0_{n, 0}) = \sum^{n}_{i}a^0_{i, 0} * X ^0_i + b^0_{i, 1}
   $$
   每组$(a, b)$参数对应一条连接线，字母i表示前一层的节点序号。

3. 同理，得到其他节点的节点数值：
   $$
   X^i_j = \sum_i a^0_{i, j} * X^0_i + b^0_{i, j}
   $$
   字母$j$表示这一层节点的序号

4. 类似的，构造多层网络

   <img src="C:\Users\qyypy\AppData\Roaming\Typora\typora-user-images\image-20231130233218576.png" alt="image-20231130233218576" style="zoom:50%;" />

   此时节点的传播公式变成：
   $$
   X^{k + 1}_{j} = \sum_ia^k_{i, j} * X^k_i + b^k_{i, j}
   $$
   字母$k$表示网络层数。

5. 图像信息通过网络传播公式传到最后一层，也称为输出层。公式参数$(a, b)$也称网络参数，输出层刚好有是个参数，表示从 $0$ 到 $9$ 十个数字。

6. 最后一层节点上的数值应为概率。
   由于网络参数$(a, b)$都是任意的，所以节点上的数值也都是任意的。为了满足概率的条件：$0 \le p_i \le 1$ ，且$\sum p_i=1$，我们需要做一次数学变换来达到目的。

   > 输出节点归一化（softmax归一化）：
   > 优先用自然常数$e$对每个$X$做指数运算$e^X$，这样得到的数都为正数，然后再拿值得总和$\sum e^{X_i}$ 作为分母，便可以得到大于$0$小于$1$的数组。

7. 此时的得到的“概率”数组此时并不是真正的概率，为了使它真正包含概率含义，我们需要对其进行“训练”：

   > 我们让神经网络对数据集中的图片进行计算，因为网络参数是随机的，所以每次输出的“概率分布”也是随机的，对于一张特定的图片，我们在已经知道这张图片代表的数字的前提下，得到它的概率分布，而真实的概率分布应该为其特定的数字概率值为1，其余为0。我们的目的就是缩小计算得到的概率分布和真实概率分布的差值。
   >
   > 如何缩小？调整网络参数$(a, b)$的值，这里有多种算法，例如梯度下降算法、Adam算法等。不论采用那种算法，$(a, b)$的值都是可以求解的。此时，神经网络问题就变成了最优化问题。
   >
   > 经过数据集中几万张图片的训练，得到一组合适的参数，那么此时神经网络就具有了预测的能力。
   >
   > 以上过程即为“训练”。

回顾：先把图片拆分成一维像素阵列，输入到神经网络，通过节点间的计算公式，图像信息传播到输出层，再通过$softmax$归一化，得到一个概率分布，再通过大量图像数据的训练，我们不断调整网络参数，让这个概率分布更接近真实值。

所以神经网络的本质就是一个数学函数，训练的过程就是不断调整函数中的参数。

为了提高训练效率，我们通常将多张图片打包成一个批次发送给神经网络，这个批次也称为batch

由于神经网络的节点计算公式是线性的，所以网络的总输入和总输出也是线性的，但是对于愈多问题，输入和输出存在着非线性，为了使线性的计算公式具有非线性行为，我们需要引入一些非线性，简单的做法是在节点的数值上再套一个非线性函数，这个非线性函数也称为激活函数，激活函数有多种选择，只要为非线性即可：

<img src="C:\Users\qyypy\AppData\Roaming\Typora\typora-user-images\image-20231201000742315.png" alt="image-20231201000742315" style="zoom: 25%;" />

#### 下载所需库

 使用pip安装numpy torch torchvision matplotlib四个库

```shell
pip install numpy torch torchvision matplotlib
```

